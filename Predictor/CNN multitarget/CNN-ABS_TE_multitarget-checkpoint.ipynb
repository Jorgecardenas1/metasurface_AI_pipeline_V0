{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4baa8720-2b4b-42d4-ad9b-9c850cbeea6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys  \n",
    "sys.path.insert(0, r\"C:\\\\Users\\jorge\\\\Documents\\\\Projects Jorge C\\\\DRUIDA PROJECT\\\\POC\\\\druida_V01\\\\src\\\\\")\n",
    "\n",
    "import os\n",
    "\n",
    "from __future__ import print_function\n",
    "#from Utilities.SaveAnimation import Video\n",
    "\n",
    "\n",
    "\n",
    "from druida import Stack\n",
    "from druida import setup\n",
    "\n",
    "from druida.DataManager import datamanager\n",
    "from druidaHFSS.modules import tools\n",
    "from druida.tools import utils\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizer\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81271b6e-4895-4900-ac21-3afe6acfedd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x19eac61ab10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "torch.manual_seed(99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30767414-f3be-410c-9ecb-46075ce10cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"run_name\",type=str)\n",
    "parser.add_argument(\"epochs\",type=int)\n",
    "parser.add_argument(\"batch_size\",type=int)\n",
    "parser.add_argument(\"workers\",type=int)\n",
    "parser.add_argument(\"gpu_number\",type=int)\n",
    "parser.add_argument(\"device\",type=str)\n",
    "parser.add_argument(\"learning_rate\",type=float)\n",
    "parser.add_argument(\"condition_len\",type=float) #This defines the length of our conditioning vector\n",
    "parser.add_argument(\"metricType\",type=float) #This defines the length of our conditioning vector\n",
    "\n",
    "parser.run_name = \"Predictor Training\"\n",
    "parser.epochs = 5\n",
    "parser.batch_size = 10\n",
    "parser.workers=0\n",
    "parser.gpu_number=0\n",
    "parser.image_size = 128\n",
    "parser.dataset_path = os.path.normpath('/content/drive/MyDrive/Training_Data/Training_lite/')\n",
    "parser.device = \"cpu\"\n",
    "parser.learning_rate = 5e-6\n",
    "parser.condition_len = 10\n",
    "parser.metricType='AbsorbanceTE' #this is to be modified when training for different metrics.\n",
    "\n",
    "categories=[\"box\", \"circle\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd27aba-6330-48f0-bc70-e5480645fab1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c97f58-1dd0-413d-8878-ca0d0a6ebb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagesPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\Images\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40ed4e3-4b8a-4c70-8d07-d5be55b63535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m folders\u001b[38;5;241m=\u001b[39mglob(imagesPath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*/\u001b[39m\u001b[38;5;124m\"\u001b[39m, recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m files\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(folders)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "folders=glob(imagesPath+\"/*/\", recursive = True)\n",
    "files=[]\n",
    "\n",
    "print(folders)\n",
    "for folder in folders:\n",
    "    \n",
    "    if folder != imagesPath+\"\\\\\"+ \"processed\\\\\":\n",
    "        files=(files+glob(folder+\"/*\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd9221-451d-45b4-a896-f10278802029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for file in files:\n",
    "    fileName_absolute = os.path.basename(file) \n",
    "    path=os.path.dirname(file)\n",
    "\n",
    "    #ROI is \n",
    "    image_rgb=tools.cropImage( file,image_path=path,\n",
    "                              image_name=fileName_absolute,\n",
    "                              output_path=imagesPath, \n",
    "                             resize_dim=(512,512))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73520e56-2b92-4458-b376-70379abf3a05",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Load Images\n",
    "<p style=\"font-size: 16px; color: blue;\">Here we create a custom dataset which provides extra information of each image and batch</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bf01d2-7df8-4cbf-a546-0cbb0ba45207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boxImagesPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\Images Jorge Cardenas\\\\\"\n",
    "DataPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\Exports\\\\output\\\\\"\n",
    "simulationData=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\DBfiles\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b73f9625-1f11-483e-81ff-b95522783d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = utils.get_data_with_labels(512, 512,0.95, boxImagesPath,parser.batch_size, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e35e40-541e-42f1-bc9c-976b96719114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('box', 'cross', 'box', 'circ', 'box', 'box', 'circ', 'cross', 'box', 'cross')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Visualizing a sample\n",
    "data,target,path,categories = next(iter(dataloader))\n",
    "print(categories)\n",
    "image = data.detach().cpu().permute(0, 2, 3,1).numpy()\n",
    "images = (image * 255).round().astype(\"uint8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57e0749c-0fec-4da2-ab48-5449ef1dc544",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(images[0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "759a23b0-0027-43a2-baae-bfbf9a027e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Stack.Trainer(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e10998e-1605-4dd2-8a1c-0a7f6d1597de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7b6201-762b-40a4-925f-a084011ef2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of a conditioning shape\n",
    "\"\"\"this conditioning must be built during training\"\"\"\n",
    "conditioning=torch.ones(1,parser.batch_size,parser.condition_len)\n",
    "conditioning.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf149b-914d-4694-96e0-00c7f662d62b",
   "metadata": {},
   "source": [
    "## Loading our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da05eb0e-86ef-46c5-b8b7-2f519cfc4eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predictor_CNN(\n",
       "  (l1): Linear(in_features=10, out_features=49152, bias=False)\n",
       "  (conv1): Conv2d(6, 8, kernel_size=(6, 6), stride=(2, 2), padding=(4, 4), bias=False)\n",
       "  (conv2): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(6, 6), stride=(2, 2), padding=(5, 5), bias=False)\n",
       "  (conv4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (conv6): Conv2d(16, 32, kernel_size=(6, 6), stride=(2, 2), padding=(4, 4), bias=False)\n",
       "  (conv7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (conv9): Conv2d(32, 64, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
       "  (conv10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "  (conv12): Conv2d(64, 128, kernel_size=(2, 2), stride=(1, 1), bias=False)\n",
       "  (l2): Linear(in_features=139392, out_features=3000, bias=False)\n",
       "  (dropout2): Dropout(p=0.2, inplace=False)\n",
       "  (l4): Linear(in_features=3000, out_features=601, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "fwd_test = Stack.Predictor_CNN(cond_input_size=parser.condition_len, \n",
    "                               ngpu=0, image_size=parser.image_size ,\n",
    "                               output_size=8, channels=3,\n",
    "                               features_num=3000,\n",
    "                               dropout=0.2, \n",
    "                               Y_prediction_size=601) #size of the output vector in this case frenquency points\n",
    "\n",
    "fwd_test.apply(weights_init)\n",
    "\n",
    "\"\"\"using weigth decay regularization\"\"\"\n",
    "opt = optimizer.Adam(fwd_test.parameters(), lr=parser.learning_rate, betas=(0.5, 0.999),weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fwd_test.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde542c9-f766-4538-8625-90c2c6fb8c4c",
   "metadata": {},
   "source": [
    "## Join simulation data\n",
    "<p style=\"font-size: 16px; color: blue;\">We need to have access to other additional simulation data which could be helpful to build our conditioning.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cda5e1a-7844-4fe6-a78b-c3d81178c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_simulationData():\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in glob.glob(simulationData+\"*.csv\"): \n",
    "        df2 = pd.read_csv(file)\n",
    "        df = pd.concat([df, df2], ignore_index=True)\n",
    "    \n",
    "    df.to_csv('out.csv',index=False)\n",
    "    \n",
    "join_simulationData()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "228e2413-3b68-4de3-aacd-a0443efbfdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 52\u001b[0m\n\u001b[0;32m     47\u001b[0m         arr\u001b[38;5;241m.\u001b[39mappend([geometry,surfacetype,materialconductor,materialsustrato,sustratoHeight,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[1;32m---> 52\u001b[0m conditions\u001b[38;5;241m=\u001b[39mset_conditioning(target, path, categories)\n\u001b[0;32m     53\u001b[0m conditions\n",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m, in \u001b[0;36mset_conditioning\u001b[1;34m(target, path, categories)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_conditioning\u001b[39m(target,path,categories):\n\u001b[1;32m----> 9\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m     arr\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx,name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(path):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1723\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1724\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\AI\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:586\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "Substrates={\"Rogers RT/duroid 5880 (tm)\":0}\n",
    "Materials={\"copper\":0,\"pec\":1}\n",
    "Surfacetypes={\"Reflective\":0,\"Transmissive\":1}\n",
    "TargetGeometries={\"circ\":0,\"box\":1, \"cross\":2}\n",
    "           \n",
    "def set_conditioning(target,path,categories):\n",
    "    df = pd.read_csv(\"out.csv\")\n",
    "    arr=[]\n",
    "\n",
    "    for idx,name in enumerate(path):\n",
    "        series=name.split('_')[-1].split('.')[0]\n",
    "        batch=name.split('_')[4]\n",
    "        iteration=series.split('-')[-1]\n",
    "        row=df[(df['sim_id']==batch) & (df['iteration']==int(iteration))  ]\n",
    "\n",
    "        \n",
    "        target_val=target[idx]\n",
    "        category=categories[idx]\n",
    "        geometry=TargetGeometries[category]\n",
    "        \n",
    "        \"\"\"\"\n",
    "        surface type: reflective, transmissive\n",
    "        layers: conductor and conductor material / Substrate information\n",
    "        \"\"\"\n",
    "        surfacetype=row[\"type\"].values[0]\n",
    "        surfacetype=Surfacetypes[surfacetype]\n",
    "        \n",
    "        layers=row[\"layers\"].values[0]\n",
    "        layers= layers.replace(\"'\", '\"')\n",
    "        layer=json.loads(layers)\n",
    "        \n",
    "        materialconductor=Materials[layer['conductor']['material']]\n",
    "        materialsustrato=Substrates[layer['substrate']['material']]\n",
    "        \n",
    "        \n",
    "        if (target_val==2): #is cross. Because an added variable to the desing \n",
    "            \n",
    "            sustratoHeight= json.loads(row[\"paramValues\"].values[0])\n",
    "            sustratoHeight= sustratoHeight[-2]\n",
    "        else:\n",
    "        \n",
    "            sustratoHeight= json.loads(row[\"paramValues\"].values[0])\n",
    "            sustratoHeight= sustratoHeight[-1]\n",
    "        \n",
    "        arr.append([geometry,surfacetype,materialconductor,materialsustrato,sustratoHeight,1,1,1,1,1])\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "conditions=set_conditioning(target, path, categories)\n",
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae8b0c-80f1-4a17-82c6-d17bde45806d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### #File reading conf\n",
    "a = []\n",
    "idx=0\n",
    "iters=0\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch in range(parser.epochs):\n",
    "    x=0\n",
    "    running_loss = 0.0\n",
    "    i=0\n",
    "    print('Epoch {}/{}'.format(epoch, parser.epochs - 1))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    \n",
    "    dataloader = utils.get_data_with_labels(512, 512,0.9, boxImagesPath,parser.batch_size,drop_last=True)\n",
    "\n",
    "\n",
    "    for data in tqdm(dataloader):\n",
    "        \n",
    "        inputs, classes, names, classes_types = data\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        #Loading data\n",
    "        a = []\n",
    "        idx=0\n",
    "        \n",
    "        \"\"\"lookup for data corresponding to every image in training batch\"\"\"\n",
    "        for name in names:\n",
    "            series=name.split('_')[-1].split('.')[0]\n",
    "            batch=name.split('_')[4]\n",
    "            for name in glob.glob(DataPath+batch+'\\\\files\\\\'+'/'+parser.metricType+'*'+series+'.csv'): \n",
    "                \n",
    "                #loading the absorption data\n",
    "                train = pd.read_csv(name)\n",
    "                values=np.array(train.values.T)\n",
    "                a.append(values[1])\n",
    "                \n",
    "                \n",
    "        a=np.array(a)     \n",
    "        \n",
    "        conditioningArray=torch.FloatTensor(set_conditioning(target, path, categories))\n",
    "\n",
    "        if conditioningArray.shape[1]==parser.condition_len:\n",
    "            \n",
    "            outmap_min, _ = torch.min(conditioningArray, dim=1, keepdim=True)\n",
    "            outmap_max, _ = torch.max(conditioningArray, dim=1, keepdim=True)\n",
    "            conditioningTensor = (conditioningArray - outmap_min) / (outmap_max - outmap_min)\n",
    "\n",
    "            y_predicted=fwd_test(input_=inputs, conditioning=conditioningTensor, b_size=inputs.shape[0])\n",
    "            y_predicted=torch.nn.functional.normalize(y_predicted, p=2.0, dim = 1)\n",
    "\n",
    "            y_truth = torch.tensor(a)\n",
    "\n",
    "            #error\n",
    "\n",
    "            errD_real = criterion(y_predicted.float(), y_truth.float())\n",
    "            errD_real.backward()\n",
    "            loss=errD_real.item()\n",
    "            opt.step()\n",
    "            scale = torch.tensor([10.0])\n",
    "\n",
    "            running_loss +=loss*inputs.size(0)\n",
    "\n",
    "\n",
    "            x += 1\n",
    "            i = i+1\n",
    "\n",
    "\n",
    "            if i % 10 == 5:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss / 10:.3f} running loss:  {running_loss / 10:.3f}')\n",
    "\n",
    "            iters += 1\n",
    "        else:\n",
    "        \n",
    "            break\n",
    "    \n",
    "    loss_values.append(running_loss)\n",
    "    epoch_values.append(epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ae30c-4682-4178-b292-fe93a49dcfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = './trainedModelTE_abs_Multitarget.pth'\n",
    "torch.save(fwd_test.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde8d83-4f47-4090-a986-f0b29d6401d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_values)\n",
    "np.savetxt('loss_ABS_TE.out', loss_values, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae19ef-a951-43cd-b3bc-101875142fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c03be-cdb9-4550-ab06-47e62d770cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
