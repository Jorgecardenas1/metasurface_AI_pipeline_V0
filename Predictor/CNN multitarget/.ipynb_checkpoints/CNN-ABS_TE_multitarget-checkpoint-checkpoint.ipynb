{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4baa8720-2b4b-42d4-ad9b-9c850cbeea6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys  \n",
    "sys.path.insert(0, r\"C:\\\\Users\\jorge\\\\Documents\\\\Projects Jorge C\\\\DRUIDA PROJECT\\\\POC\\\\druida_V01\\\\src\\\\\")\n",
    "\n",
    "import os\n",
    "\n",
    "from __future__ import print_function\n",
    "#from Utilities.SaveAnimation import Video\n",
    "\n",
    "\n",
    "\n",
    "from druida import Stack\n",
    "from druida import setup\n",
    "\n",
    "from druida.DataManager import datamanager\n",
    "from druidaHFSS.modules import tools\n",
    "from druida.tools import utils\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optimizer\n",
    "\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81271b6e-4895-4900-ac21-3afe6acfedd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "torch.manual_seed(999)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30767414-f3be-410c-9ecb-46075ce10cf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"run_name\",type=str)\n",
    "parser.add_argument(\"epochs\",type=int)\n",
    "parser.add_argument(\"batch_size\",type=int)\n",
    "parser.add_argument(\"workers\",type=int)\n",
    "parser.add_argument(\"gpu_number\",type=int)\n",
    "parser.add_argument(\"device\",type=str)\n",
    "parser.add_argument(\"learning_rate\",type=float)\n",
    "parser.add_argument(\"condition_len\",type=float) #This defines the length of our conditioning vector\n",
    "parser.add_argument(\"metricType\",type=float) #This defines the length of our conditioning vector\n",
    "\n",
    "parser.run_name = \"Predictor Training\"\n",
    "parser.epochs = 15\n",
    "parser.batch_size = 5\n",
    "parser.workers=0\n",
    "parser.gpu_number=0\n",
    "parser.image_size = 512\n",
    "parser.dataset_path = os.path.normpath('/content/drive/MyDrive/Training_Data/Training_lite/')\n",
    "parser.device = \"cpu\"\n",
    "parser.learning_rate = 5e-6\n",
    "parser.condition_len = 10\n",
    "parser.metricType='AbsorbanceTE' #this is to be modified when training for different metrics.\n",
    "\n",
    "categories=[\"box\", \"circle\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd27aba-6330-48f0-bc70-e5480645fab1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c97f58-1dd0-413d-8878-ca0d0a6ebb0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imagesPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\Images\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e40ed4e3-4b8a-4c70-8d07-d5be55b63535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m folders\u001b[38;5;241m=\u001b[39mglob(imagesPath\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/*/\u001b[39m\u001b[38;5;124m\"\u001b[39m, recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m files\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(folders)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "folders=glob(imagesPath+\"/*/\", recursive = True)\n",
    "files=[]\n",
    "\n",
    "print(folders)\n",
    "for folder in folders:\n",
    "    \n",
    "    if folder != imagesPath+\"\\\\\"+ \"processed\\\\\":\n",
    "        files=(files+glob(folder+\"/*\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cd9221-451d-45b4-a896-f10278802029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for file in files:\n",
    "    fileName_absolute = os.path.basename(file) \n",
    "    path=os.path.dirname(file)\n",
    "\n",
    "    #ROI is \n",
    "    image_rgb=tools.cropImage( file,image_path=path,\n",
    "                              image_name=fileName_absolute,\n",
    "                              output_path=imagesPath, \n",
    "                             resize_dim=(512,512))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73520e56-2b92-4458-b376-70379abf3a05",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## Load Images\n",
    "<p style=\"font-size: 16px; color: blue;\">Here we create a custom dataset which provides extra information of each image and batch</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bf01d2-7df8-4cbf-a546-0cbb0ba45207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boxImagesPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\Images Jorge Cardenas 512\\\\\"\n",
    "DataPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\Exports\\\\output\\\\\"\n",
    "simulationData=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\DBfiles\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73f9625-1f11-483e-81ff-b95522783d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataloader = utils.get_data_with_labels(512, 512,0.95, boxImagesPath,parser.batch_size, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e35e40-541e-42f1-bc9c-976b96719114",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Visualizing a sample\n",
    "data,target,path,categories = next(iter(dataloader))\n",
    "print(categories)\n",
    "image = data.detach().cpu().permute(0, 2, 3,1).numpy()\n",
    "images = (image * 255).round().astype(\"uint8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e0749c-0fec-4da2-ab48-5449ef1dc544",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(images[0])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759a23b0-0027-43a2-baae-bfbf9a027e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Stack.Trainer(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e10998e-1605-4dd2-8a1c-0a7f6d1597de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b6201-762b-40a4-925f-a084011ef2c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Example of a conditioning shape\n",
    "\"\"\"this conditioning must be built during training\"\"\"\n",
    "conditioning=torch.ones(1,parser.batch_size,parser.condition_len)\n",
    "conditioning.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf149b-914d-4694-96e0-00c7f662d62b",
   "metadata": {},
   "source": [
    "## Loading our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da05eb0e-86ef-46c5-b8b7-2f519cfc4eb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optimizer\n",
    "\n",
    "fwd_test = Stack.Predictor_CNN(cond_input_size=parser.condition_len, \n",
    "                               ngpu=0, image_size=parser.image_size ,\n",
    "                               output_size=8, channels=3,\n",
    "                               features_num=3000,\n",
    "                               dropout=0.2, \n",
    "                               Y_prediction_size=601) #size of the output vector in this case frenquency points\n",
    "\n",
    "fwd_test.apply(weights_init)\n",
    "\n",
    "\"\"\"using weigth decay regularization\"\"\"\n",
    "opt = optimizer.Adam(fwd_test.parameters(), lr=parser.learning_rate, betas=(0.5, 0.999),weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "fwd_test.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde542c9-f766-4538-8625-90c2c6fb8c4c",
   "metadata": {},
   "source": [
    "## Join simulation data\n",
    "<p style=\"font-size: 16px; color: blue;\">We need to have access to other additional simulation data which could be helpful to build our conditioning.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda5e1a-7844-4fe6-a78b-c3d81178c7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_simulationData():\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for file in glob.glob(simulationData+\"*.csv\"): \n",
    "        df2 = pd.read_csv(file)\n",
    "        df = pd.concat([df, df2], ignore_index=True)\n",
    "    \n",
    "    df.to_csv('out.csv',index=False)\n",
    "    \n",
    "join_simulationData()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228e2413-3b68-4de3-aacd-a0443efbfdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "Substrates={\"Rogers RT/duroid 5880 (tm)\":0}\n",
    "Materials={\"copper\":0,\"pec\":1}\n",
    "Surfacetypes={\"Reflective\":0,\"Transmissive\":1}\n",
    "TargetGeometries={\"circ\":0,\"box\":1, \"cross\":2}\n",
    "           \n",
    "def set_conditioning(target,path,categories):\n",
    "    df = pd.read_csv(\"out.csv\")\n",
    "    arr=[]\n",
    "\n",
    "    for idx,name in enumerate(path):\n",
    "        series=name.split('_')[-1].split('.')[0]\n",
    "        batch=name.split('_')[4]\n",
    "        iteration=series.split('-')[-1]\n",
    "        row=df[(df['sim_id']==batch) & (df['iteration']==int(iteration))  ]\n",
    "\n",
    "        \n",
    "        target_val=target[idx]\n",
    "        category=categories[idx]\n",
    "        geometry=TargetGeometries[category]\n",
    "        \n",
    "        \"\"\"\"\n",
    "        surface type: reflective, transmissive\n",
    "        layers: conductor and conductor material / Substrate information\n",
    "        \"\"\"\n",
    "        surfacetype=row[\"type\"].values[0]\n",
    "        surfacetype=Surfacetypes[surfacetype]\n",
    "        \n",
    "        layers=row[\"layers\"].values[0]\n",
    "        layers= layers.replace(\"'\", '\"')\n",
    "        layer=json.loads(layers)\n",
    "        \n",
    "        materialconductor=Materials[layer['conductor']['material']]\n",
    "        materialsustrato=Substrates[layer['substrate']['material']]\n",
    "        \n",
    "        \n",
    "        if (target_val==2): #is cross. Because an added variable to the desing \n",
    "            \n",
    "            sustratoHeight= json.loads(row[\"paramValues\"].values[0])\n",
    "            sustratoHeight= sustratoHeight[-2]\n",
    "        else:\n",
    "        \n",
    "            sustratoHeight= json.loads(row[\"paramValues\"].values[0])\n",
    "            sustratoHeight= sustratoHeight[-1]\n",
    "        \n",
    "        arr.append([geometry,surfacetype,materialconductor,materialsustrato,sustratoHeight,1,1,1,1,1])\n",
    "    \n",
    "    return arr\n",
    "\n",
    "\n",
    "conditions=set_conditioning(target, path, categories)\n",
    "conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae8b0c-80f1-4a17-82c6-d17bde45806d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### #File reading conf\n",
    "a = []\n",
    "idx=0\n",
    "iters=0\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch in range(parser.epochs):\n",
    "    x=0\n",
    "    running_loss = 0.0\n",
    "    i=0\n",
    "    print('Epoch {}/{}'.format(epoch, parser.epochs - 1))\n",
    "    print('-' * 10)\n",
    "    \n",
    "    \n",
    "    dataloader = utils.get_data_with_labels(512, 512,0.9, boxImagesPath,parser.batch_size,drop_last=True)\n",
    "\n",
    "\n",
    "    for data in tqdm(dataloader):\n",
    "        \n",
    "        inputs, classes, names, classes_types = data\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        #Loading data\n",
    "        a = []\n",
    "        idx=0\n",
    "        \n",
    "        \"\"\"lookup for data corresponding to every image in training batch\"\"\"\n",
    "        for name in names:\n",
    "            series=name.split('_')[-1].split('.')[0]\n",
    "            batch=name.split('_')[4]\n",
    "            for name in glob.glob(DataPath+batch+'\\\\files\\\\'+'/'+parser.metricType+'*'+series+'.csv'): \n",
    "                \n",
    "                #loading the absorption data\n",
    "                train = pd.read_csv(name)\n",
    "                values=np.array(train.values.T)\n",
    "                a.append(values[1])\n",
    "                \n",
    "                \n",
    "        a=np.array(a)     \n",
    "        \n",
    "        conditioningArray=torch.FloatTensor(set_conditioning(target, path, categories))\n",
    "\n",
    "        if conditioningArray.shape[1]==parser.condition_len:\n",
    "            \n",
    "            outmap_min, _ = torch.min(conditioningArray, dim=1, keepdim=True)\n",
    "            outmap_max, _ = torch.max(conditioningArray, dim=1, keepdim=True)\n",
    "            conditioningTensor = (conditioningArray - outmap_min) / (outmap_max - outmap_min)\n",
    "\n",
    "            y_predicted=fwd_test(input_=inputs, conditioning=conditioningTensor, b_size=inputs.shape[0])\n",
    "            y_predicted=torch.nn.functional.normalize(y_predicted, p=2.0, dim = 1)\n",
    "\n",
    "            y_truth = torch.tensor(a)\n",
    "\n",
    "            #error\n",
    "\n",
    "            errD_real = criterion(y_predicted.float(), y_truth.float())\n",
    "            errD_real.backward()\n",
    "            loss=errD_real.item()\n",
    "            opt.step()\n",
    "            scale = torch.tensor([10.0])\n",
    "\n",
    "            running_loss +=loss*inputs.size(0)\n",
    "\n",
    "\n",
    "            x += 1\n",
    "            i = i+1\n",
    "\n",
    "\n",
    "            if i % 10 == 5:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {loss / 10:.3f} running loss:  {running_loss / 10:.3f}')\n",
    "\n",
    "            iters += 1\n",
    "        else:\n",
    "        \n",
    "            break\n",
    "    \n",
    "    loss_values.append(running_loss)\n",
    "    epoch_values.append(epoch)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ae30c-4682-4178-b292-fe93a49dcfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = './trainedModelTE_abs_Multitarget.pth'\n",
    "torch.save(fwd_test.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecde8d83-4f47-4090-a986-f0b29d6401d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_values)\n",
    "np.savetxt('loss_ABS_TE.out', loss_values, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ae19ef-a951-43cd-b3bc-101875142fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c03be-cdb9-4550-ab06-47e62d770cde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
