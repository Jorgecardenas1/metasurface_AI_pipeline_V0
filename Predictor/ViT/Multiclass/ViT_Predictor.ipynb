{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c43fc8-9128-4c0f-a90c-07e4a55fe916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys  \n",
    "sys.path.insert(0, r\"C:\\\\Users\\jorge\\\\Documents\\\\Projects Jorge C\\\\DRUIDA PROJECT\\\\POC\\\\druida_V01\\\\src\\\\\")\n",
    "\n",
    "import os\n",
    "\n",
    "from __future__ import print_function\n",
    "#from Utilities.SaveAnimation import Video\n",
    "\n",
    "\n",
    "\n",
    "from druida import Stack\n",
    "from druida import setup\n",
    "\n",
    "from druida.DataManager import datamanager\n",
    "from druidaHFSS.modules import tools\n",
    "from druida.tools import utils\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.offsetbox import OffsetImage,AnchoredOffsetbox\n",
    "import matplotlib.image as image\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import argparse\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38853f24-6bad-4ca5-b791-c6f47f1bdf14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"run_name\",type=str)\n",
    "parser.add_argument(\"epochs\",type=int)\n",
    "parser.add_argument(\"batch_size\",type=int)\n",
    "parser.add_argument(\"workers\",type=int)\n",
    "parser.add_argument(\"gpu_number\",type=int)\n",
    "parser.add_argument(\"device\",type=str)\n",
    "parser.add_argument(\"learning_rate\",type=float)\n",
    "parser.add_argument(\"condition_len\",type=float) #This defines the length of our conditioning vector\n",
    "parser.add_argument(\"metricType\",type=float) #This defines the length of our conditioning vector\n",
    "\n",
    "parser.run_name = \"DDPM_Uncondtional\"\n",
    "parser.epochs = 6\n",
    "parser.batch_size = 10\n",
    "parser.workers=0\n",
    "parser.gpu_number=0\n",
    "parser.image_size = 512\n",
    "parser.dataset_path = os.path.normpath('/content/drive/MyDrive/Training_Data/Training_lite/')\n",
    "parser.device = \"cpu\"\n",
    "parser.learning_rate = 1e-6\n",
    "parser.condition_len = 10\n",
    "parser.metricType='AbsorbanceTM' #this is to be modified when training for different metrics.\n",
    "\n",
    "categories=[\"box\", \"circle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9348da90-5629-46ed-85a0-3f1e2430c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TM = './trainedModelTM_abs_Multitarget_cross.pth'\n",
    "PATH_TE = './trainedModelTE_abs_Multitarget.pth'\n",
    "\n",
    "boxImagesPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\testImages\\\\\"\n",
    "DataPath=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\Exports\\\\output\\\\\"\n",
    "simulationData=\"C:\\\\Users\\\\jorge\\\\Dropbox\\\\Public\\\\MetasufacesData\\\\DBfiles\\\\\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
